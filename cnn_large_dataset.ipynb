{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2a40b1-fc3e-48d5-9982-10a91edca4a1",
   "metadata": {
    "id": "4a2a40b1-fc3e-48d5-9982-10a91edca4a1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ff35ba-1c73-41a7-937e-a59e1370d292",
   "metadata": {
    "id": "20ff35ba-1c73-41a7-937e-a59e1370d292",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ea0427-e138-4d5f-bebd-d924c3435c88",
   "metadata": {
    "id": "85ea0427-e138-4d5f-bebd-d924c3435c88",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a149414-61d8-4e79-80c2-295b43f9ee55",
   "metadata": {
    "id": "3a149414-61d8-4e79-80c2-295b43f9ee55",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DisasterTypeDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (string): Directory with all post-disaster images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_filenames = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]  # Filter out directories\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        disaster_types = [self.extract_disaster_type(f) for f in self.image_filenames]\n",
    "        self.labels = self.label_encoder.fit_transform(disaster_types)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "        image = Image.open(img_name)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def extract_disaster_type(self, filename):\n",
    "        parts = filename.split('_')\n",
    "        first_part = parts[0]\n",
    "        disaster_types = [\"hurricane\", \"fire\", \"wind\", \"flooding\", \"tsunami\", \"earthquake\"] # There is no wind in data, but web page said there is\n",
    "        for disaster_type in disaster_types:\n",
    "            if disaster_type in first_part:\n",
    "                return disaster_type\n",
    "        return \"unknown\"\n",
    "\n",
    "    def get_disaster_types(self):\n",
    "        return self.label_encoder.classes_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5a0ba0-93bf-4cc3-a807-30885e84f6f8",
   "metadata": {
    "id": "ec5a0ba0-93bf-4cc3-a807-30885e84f6f8"
   },
   "outputs": [],
   "source": [
    "# Add more transformations methods (e.g. random rotations, flips, and color adjustments)\n",
    "def get_augmented_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def distillation_loss(student_outputs, teacher_outputs, labels, T=2.0, alpha=0.7, weight_loss_factor=0.5):\n",
    "    soft_loss = nn.KLDivLoss()(F.log_softmax(student_outputs/T, dim=1),\n",
    "                               F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T)\n",
    "    hard_loss = F.cross_entropy(student_outputs, labels) * (1. - alpha)\n",
    "    weight_tensor = torch.full((6,), weight_loss_factor, device=student_outputs.device)  # Assuming 6 classes\n",
    "    weight_loss = F.cross_entropy(student_outputs, labels, weight=weight_tensor)\n",
    "\n",
    "    return soft_loss + hard_loss + weight_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d3807a-d140-4647-8500-80473824231d",
   "metadata": {
    "id": "48d3807a-d140-4647-8500-80473824231d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "        self.fc1 = nn.Linear(512 * 16 * 16, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.batchnorm1(self.conv1(x.float()))))\n",
    "        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.batchnorm4(self.conv4(x))))\n",
    "        x = x.view(-1, 512 * 16 * 16)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c669b167-e7c3-45cb-8b42-481d43f1e7ad",
   "metadata": {
    "id": "c669b167-e7c3-45cb-8b42-481d43f1e7ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train_model(model, teacher_model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    teacher_model.eval()\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            student_outputs = model(images)\n",
    "            teacher_outputs = teacher_model(images)\n",
    "            loss = distillation_loss(student_outputs, teacher_outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(student_outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_acc:.2f}%')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f'Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d5ee2d-b6df-431a-afb6-365fdb19c48d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "14d5ee2d-b6df-431a-afb6-365fdb19c48d",
    "outputId": "eb8a91e4-3d21-4200-dd81-0a956ab320f5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/root/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py:2919: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.8831, Accuracy: 81.83%\n",
      "Validation Loss: 0.5641, Accuracy: 81.53%\n",
      "Epoch 2/10, Loss: 0.6640, Accuracy: 89.20%\n",
      "Validation Loss: 0.3061, Accuracy: 91.20%\n",
      "Epoch 3/10, Loss: 0.5757, Accuracy: 91.58%\n",
      "Validation Loss: 0.3140, Accuracy: 90.76%\n",
      "Epoch 4/10, Loss: 0.4629, Accuracy: 95.45%\n",
      "Validation Loss: 0.1754, Accuracy: 96.07%\n",
      "Epoch 5/10, Loss: 0.4335, Accuracy: 96.31%\n",
      "Validation Loss: 0.1680, Accuracy: 97.38%\n",
      "Epoch 6/10, Loss: 0.4139, Accuracy: 96.93%\n",
      "Validation Loss: 0.1448, Accuracy: 98.25%\n",
      "Epoch 7/10, Loss: 0.3971, Accuracy: 97.55%\n",
      "Validation Loss: 0.1442, Accuracy: 97.96%\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    image_dir = 'post_disaster'\n",
    "    transform = get_augmented_transform()\n",
    "    dataset = DisasterTypeDataset(image_dir, transform=transform)\n",
    "    num_classes = len(set(dataset.labels))\n",
    "\n",
    "    train_set, val_set, test_set = random_split(dataset, [int(0.7 * len(dataset)),\n",
    "                                                           int(0.15 * len(dataset)),\n",
    "                                                           len(dataset) - int(0.7 * len(dataset)) - int(0.15 * len(dataset))])\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
    "\n",
    "    teacher_model = resnet18(pretrained=True)\n",
    "    teacher_model.fc = nn.Linear(teacher_model.fc.in_features, num_classes)\n",
    "\n",
    "    student_model = CNN_model(num_classes)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_teacher = optim.Adam(teacher_model.parameters(), lr=0.001)\n",
    "    optimizer_student = optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "    train_model(teacher_model, student_model, train_loader, val_loader, criterion, optimizer_teacher, 10)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QELAdlb0dapK",
   "metadata": {
    "id": "QELAdlb0dapK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
